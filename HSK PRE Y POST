# %%
import sys
import os
import pandas as pd
import importlib
print("Ruta actual:", os.getcwd())

# 1) Define la ruta primero
ruta_modulo = r"C:\Users\dominh05\Documents\SIX\Modulos"
print("Ruta del m칩dulo:", ruta_modulo)

# 2) Agr칠gala a sys.path si no est치
if ruta_modulo not in sys.path:
    sys.path.insert(0, ruta_modulo)  # insert(0,...) para darle prioridad


import importlib
import Desincorporaciones

importlib.reload(Desincorporaciones)
from Desincorporaciones import desincorporaciones

hsk = pd.read_excel(r"C:\Users\dominh05\Documents\SIX\HSK\Resultados 2025\Historico Resultados HSK base Monstruosa.xlsx")
op_historico = pd.read_parquet(r"C:\Users\dominh05\Documents\SIX\Codigos_six\Comisiones\Bases Fregonas\OP_Historico Octubre 2025.parquet")
acumulado_bajas = pd.read_excel('Historico Bajas Cuenta KPI.xlsx')
final_de_comisiones = pd.read_parquet(r"C:\Users\dominh05\Documents\SIX\Codigos_six\Comisiones\Bases Fregonas\Final_de_Comisiones_Historico.parquet")
com_contrato =  pd.read_excel(r"C:\Users\dominh05\Documents\SIX\HSK\Tabulador Ene - Jun_2025 - OCTUBRE.xlsx")
df_desincorporaciones = pd.read_excel(r"C:\Users\dominh05\Documents\SIX\SA027\Catalogo GZ Octubre 2025.xlsx")


    

# %%
if 'Graduados 2024' in hsk.columns:
    hsk['Graduados 2024'] = hsk['Graduados 2024'].astype(str)
# Ordena el DataFrame hsk por 'Fecha de tabulador' de pasado a futuro
hsk['Fecha de tabulador'] = pd.to_datetime(hsk['Fecha de tabulador'])
hsk = hsk.sort_values('Fecha de tabulador')

# Obt칠n la primera aparici칩n de 'Fecha de tabulador' para cada 'CeCo'
Inicio_en_hsk = hsk.groupby('CeCo')['Fecha de tabulador'].first()

# Crea la columna 'Fecha de ingreso a HSK' usando el mapeo
hsk['Fecha de ingreso a HSK'] = hsk['CeCo'].map(Inicio_en_hsk)

# Crear un calendario de meses del 2023-01 al 칰ltimo mes en hsk
calendario = pd.date_range(start="2023-03-01", end=hsk['Fecha de tabulador'].max(), freq="MS")  # MS = Month Start

# Crear producto cartesiano de CeCos x calendario
cecos_unicos = hsk['CeCo'].unique()
multi_index = pd.MultiIndex.from_product([cecos_unicos, calendario], names=['CeCo', 'Fecha de tabulador'])
base_cecos = pd.DataFrame(index=multi_index).reset_index()

# Asegura que las columnas est치n bien nombradas y no hay columnas extra
#base_cecos = base_cecos.loc[:, ['CeCo', 'Fecha de tabulador']]

# Traer info de primera aparici칩n
info_inicial = hsk.groupby('CeCo').first().reset_index()

# Mapear columnas de primera aparici칩n
for col in ['Regi칩n','Nombre de tienda','Tipo','GZ SIX','# SK','Nombre SK','Wave']:
    if col in info_inicial.columns:
        base_cecos[col] = base_cecos['CeCo'].map(info_inicial.set_index('CeCo')[col])

# Mapear fecha de ingreso y 칰ltima aparici칩n
base_cecos['Fecha de ingreso a HSK'] = base_cecos['CeCo'].map(Inicio_en_hsk)
ultima_fecha_ceco = hsk.groupby('CeCo')['Fecha de tabulador'].max()
base_cecos['Ultima_Fecha'] = base_cecos['CeCo'].map(ultima_fecha_ceco)
# Mapear fecha de ingreso y 칰ltima aparici칩n
base_cecos['Fecha de ingreso a HSK'] = base_cecos['CeCo'].map(Inicio_en_hsk)
ultima_fecha_ceco = hsk.groupby('CeCo')['Fecha de tabulador'].max()
base_cecos['Ultima_Fecha'] = base_cecos['CeCo'].map(ultima_fecha_ceco)

# Etiquetar Before / Durante / Post
def etapa(row):
    if pd.isna(row['Fecha de ingreso a HSK']):
        return "Before HSK"
    elif row['Fecha de tabulador'] < row['Fecha de ingreso a HSK']:
        return "Before HSK"
    elif row['Fecha de tabulador'] > row['Ultima_Fecha']:
        return "Post HSK"
    else:
        return "HSK Activo"

base_cecos['Etapa'] = base_cecos.apply(etapa, axis=1)


# 游댳 Crear llave 칰nica para detectar duplicados (CeCo + Fecha)
hsk['llave'] = hsk['CeCo'].astype(str) + hsk['Fecha de tabulador'].dt.strftime('%Y-%m-%d')
base_cecos['llave'] = base_cecos['CeCo'].astype(str) + base_cecos['Fecha de tabulador'].dt.strftime('%Y-%m-%d')

# 游댳 Filtrar solo los registros de base_cecos que NO est칠n ya en hsk
base_cecos_nuevos = base_cecos[~base_cecos['llave'].isin(hsk['llave'])]

# 游댳 Concatenar hsk con los nuevos (sin duplicar los reales)
hsk = pd.concat([hsk, base_cecos_nuevos], ignore_index=True)

# 游댳 Ordenar y limpiar
hsk = hsk.sort_values('Fecha de tabulador').reset_index(drop=True)
hsk.drop(columns=['llave'], inplace=True)
base_cecos.drop(columns=['llave'], inplace=True)

# Obt칠n la primera aparici칩n de 'Tipo' para cada 'CeCo'
Ola_hsk = hsk.groupby('CeCo')['Tipo'].first()

# Crea la columna 'validacion' usando el mapeo
hsk['validacion'] = hsk['CeCo'].map(Ola_hsk)

# Crea las columnas Mes, A침o y A침o_LY
hsk['Mes'] = hsk['Fecha de tabulador'].dt.month.astype(str)
hsk['A침o'] = hsk['Fecha de tabulador'].dt.year.astype(str)
hsk['A침o_LY'] = (hsk['Fecha de tabulador'].dt.year - 1).astype(str)
hsk['Fecha'] = hsk['Fecha de tabulador']
hsk['Fecha LY'] = hsk['Fecha'] - pd.DateOffset(years=1)

# %% [markdown]
# ## Ola 3 WE

# %%
# Convierte la columna a datetime por si acaso
hsk['Fecha de tabulador'] = pd.to_datetime(hsk['Fecha de tabulador'])

# Define la fecha de corte
fecha_corte = pd.Timestamp('2025-06-01')

# Filtro para Regi칩n WE y A침o 2025 y Fecha de tabulador >= 1/6/2025
filtro_we_ola3 = (
    (hsk['Fecha de tabulador'] >= fecha_corte) &
    (hsk['A침o'] == '2025') &
    (hsk['Regi칩n'] == 'WE')
)

# Para esas filas, asigna la primera aparici칩n de Fecha de tabulador a partir de 1/6/2025 para cada CeCo
primer_fecha_ola3 = (
    hsk.loc[filtro_we_ola3]
    .groupby('CeCo')['Fecha de tabulador']
    .first()
)

# Asigna el resultado solo a las filas que cumplen el filtro
hsk.loc[filtro_we_ola3, 'Fecha de ingreso a HSK'] = hsk.loc[filtro_we_ola3, 'CeCo'].map(primer_fecha_ola3)

# 游댳 Nuevo paso: actualizar Tipo a "OLA3" para esas filas
hsk.loc[filtro_we_ola3, 'validacion'] = "OLA3"

hsk['Wave'] = hsk['validacion']

# %% [markdown]
# ## Da formato a las columnas que utilizaremos

# %%
# Normaliza tipos en hsk
hsk['A침o'] = hsk['A침o'].astype(int).astype(str)
hsk['Mes'] = hsk['Mes'].astype(int).astype(str)
hsk['CeCo'] = hsk['CeCo'].astype(str)
hsk['# SK'] = hsk['# SK'].astype(str)

# Llaves y concatenaciones en hsk
hsk['concat_ay'] = hsk['CeCo'] + hsk['Mes'] + hsk['A침o']
hsk['concat_ly'] = hsk['CeCo'] + hsk['Mes'] + (hsk['A침o'].astype(int) - 1).astype(str)
hsk['llave_proveedor_ay'] = hsk['# SK'] + hsk['Mes'] + hsk['A침o']
hsk['Nombre SK'] = hsk['Nombre SK'].astype(str)
hsk['Nombre SK'] = hsk['Nombre SK'].astype(str)
hsk['llave_proveedor_ly'] = hsk['# SK'] + hsk['Mes'] + (hsk['A침o'].astype(int) - 1).astype(str)

# Normaliza tipos en acumulado_bajas
acumulado_bajas['A침o'] = acumulado_bajas['A침o'].astype(int).astype(str)
acumulado_bajas['Mes'] = acumulado_bajas['Mes'].astype(int).astype(str)
acumulado_bajas['NUMERO DE NEGOCIO'] = acumulado_bajas['NUMERO DE NEGOCIO'].astype(str)
acumulado_bajas['NUMERO DE PROVEEDOR'] = acumulado_bajas['NUMERO DE PROVEEDOR'].astype(str)

# Llaves y concatenaciones en acumulado_bajas
acumulado_bajas['concat_ay'] = acumulado_bajas['NUMERO DE NEGOCIO'] + acumulado_bajas['Mes'] + acumulado_bajas['A침o']
acumulado_bajas['concat_ly'] = acumulado_bajas['NUMERO DE NEGOCIO'] + acumulado_bajas['Mes'] + (acumulado_bajas['A침o'].astype(int) - 1).astype(str)
acumulado_bajas['llave_proveedor_ay'] = acumulado_bajas['NUMERO DE PROVEEDOR'] + acumulado_bajas['Mes'] + acumulado_bajas['A침o']
acumulado_bajas['llave_proveedor_ly'] = acumulado_bajas['NUMERO DE PROVEEDOR'] + acumulado_bajas['Mes'] + (acumulado_bajas['A침o'].astype(int) - 1).astype(str)

# Funci칩n de asignaci칩n de bajas
def agregar_bajas_a_hsk(hsk_df, bajas_df):
    conteo_ay = bajas_df['llave_proveedor_ay'].value_counts()
    conteo_ly = bajas_df['concat_ay'].value_counts()
    
    hsk_df['baja'] = hsk_df['llave_proveedor_ay'].map(conteo_ay).fillna(0).astype(int)
    hsk_df['baja ly'] = hsk_df['concat_ly'].map(conteo_ly).fillna(0).astype(int)
    
    return hsk_df

# Uso
hsk = agregar_bajas_a_hsk(hsk, acumulado_bajas)

# Crear diccionario de mapeo a partir de com_contrato
# Asegurar que las llaves del mapeo sean texto
map_dict = dict(zip(com_contrato['No.deNegocio'].astype(str), com_contrato['Tabulador 2025']))

# Asegurar que la columna CeCo sea texto antes de mapear
hsk['tradicional'] = hsk['CeCo'].astype(str).map(map_dict)

# %% [markdown]
# # Graduados

# %%
# Para contar aparici칩n acumulada de cada CeCo (1춹, 2춹, 3춹, etc.)
hsk['Aparicion'] = hsk.groupby('CeCo').cumcount() + 1

# Tambi칠n calculamos el n칰mero m치ximo de apariciones por CeCo
max_apariciones = hsk.groupby('CeCo')['Aparicion'].transform('max')

# Reemplazamos el n칰mero de la 칰ltima aparici칩n por "칔ltima"
hsk['Aparicion'] = hsk.apply(
    lambda row: 99999999 if row['Aparicion'] == max_apariciones[row.name] else row['Aparicion'],
    axis=1
)

hsk['Status'] = "Activa"

hsk['CeCo_count'] = hsk.groupby('CeCo')['CeCo'].transform('count')
hsk = hsk.sort_values('Fecha de tabulador')


def fill_pct_nuevo(group):
    group = group.sort_values('Fecha de tabulador')  # asegurar orden correcto

    mask = (group['Etapa'] == 'HSK Activo') & (group['% Nuevo'].isna())

    # Hacer bfill solo para esas filas, usando todo el grupo
    group.loc[mask, '% Nuevo'] = group['% Nuevo'].bfill()[mask]

    return group

hsk = hsk.sort_values(['CeCo', 'Fecha de tabulador'])
hsk = hsk.groupby('CeCo', group_keys=False).apply(fill_pct_nuevo)


# Filtra el DataFrame para CeCo == '301372092' y muestra el resultado
filtro = hsk[hsk['CeCo'] == '301372092']
print(filtro)




# %%
# Ordena el DataFrame hsk por 'Fecha de tabulador' de pasado a futuro
hsk['Fecha de tabulador'] = pd.to_datetime(hsk['Fecha de tabulador'])
hsk = hsk.sort_values('Fecha de tabulador')

# Obt칠n la primera aparici칩n de 'Fecha de tabulador' para cada 'CeCo'
Inicio_en_hsk = hsk.groupby('CeCo')['Fecha de tabulador'].first()

# Crea la columna 'Fecha de ingreso a HSK' usando el mapeo
hsk['Fecha de ingreso a HSK'] = hsk['CeCo'].map(Inicio_en_hsk)

# Crear un calendario de meses del 2023-03 al 칰ltimo mes en hsk
calendario = pd.date_range(start="2023-03-01", end=hsk['Fecha de tabulador'].max(), freq="MS")  # MS = Month Start

# Crear producto cartesiano de CeCos x calendario
cecos_unicos = hsk['CeCo'].unique()
multi_index = pd.MultiIndex.from_product([cecos_unicos, calendario], names=['CeCo', 'Fecha de tabulador'])
base_cecos = pd.DataFrame(index=multi_index).reset_index()

# Asegura que las columnas est치n bien nombradas y no hay columnas extra
#base_cecos = base_cecos.loc[:, ['CeCo', 'Fecha de tabulador']]

# Traer info de primera aparici칩n
info_inicial = hsk.groupby('CeCo').first().reset_index()

# Mapear columnas de primera aparici칩n
for col in ['Regi칩n','Nombre de tienda','Tipo','GZ SIX','# SK','Nombre SK','Wave']:
    if col in info_inicial.columns:
        base_cecos[col] = base_cecos['CeCo'].map(info_inicial.set_index('CeCo')[col])

# Mapear fecha de ingreso y 칰ltima aparici칩n
base_cecos['Fecha de ingreso a HSK'] = base_cecos['CeCo'].map(Inicio_en_hsk)
ultima_fecha_ceco = hsk.groupby('CeCo')['Fecha de tabulador'].max()
base_cecos['Ultima_Fecha'] = base_cecos['CeCo'].map(ultima_fecha_ceco)
# Mapear fecha de ingreso y 칰ltima aparici칩n
base_cecos['Fecha de ingreso a HSK'] = base_cecos['CeCo'].map(Inicio_en_hsk)
ultima_fecha_ceco = hsk.groupby('CeCo')['Fecha de tabulador'].max()
base_cecos['Ultima_Fecha'] = base_cecos['CeCo'].map(ultima_fecha_ceco)

# Etiquetar Before / Durante / Post
def etapa(row):
    if pd.isna(row['Fecha de ingreso a HSK']):
        return "Before HSK"
    elif row['Fecha de tabulador'] < row['Fecha de ingreso a HSK']:
        return "Before HSK"
    elif row['Fecha de tabulador'] > row['Ultima_Fecha']:
        return "Post HSK"
    else:
        return "HSK Activo"

base_cecos['Etapa'] = base_cecos.apply(etapa, axis=1)


# 游댳 Crear llave 칰nica para detectar duplicados (CeCo + Fecha)
hsk['llave'] = hsk['CeCo'].astype(str) + hsk['Fecha de tabulador'].dt.strftime('%Y-%m-%d')
base_cecos['llave'] = base_cecos['CeCo'].astype(str) + base_cecos['Fecha de tabulador'].dt.strftime('%Y-%m-%d')

# 游댳 Filtrar solo los registros de base_cecos que NO est칠n ya en hsk
base_cecos_nuevos = base_cecos[~base_cecos['llave'].isin(hsk['llave'])]

# 游댳 Concatenar hsk con los nuevos (sin duplicar los reales)
hsk = pd.concat([hsk, base_cecos_nuevos], ignore_index=True)

# 游댳 Ordenar y limpiar
hsk = hsk.sort_values('Fecha de tabulador').reset_index(drop=True)
hsk.drop(columns=['llave'], inplace=True)
base_cecos.drop(columns=['llave'], inplace=True)

# Obt칠n la primera aparici칩n de 'Tipo' para cada 'CeCo'
Ola_hsk = hsk.groupby('CeCo')['Tipo'].first()

# Crea la columna 'validacion' usando el mapeo
hsk['validacion'] = hsk['CeCo'].map(Ola_hsk)

# Crea las columnas Mes, A침o y A침o_LY
hsk['Mes'] = hsk['Fecha de tabulador'].dt.month.astype(str)
hsk['A침o'] = hsk['Fecha de tabulador'].dt.year.astype(str)
hsk['A침o_LY'] = (hsk['Fecha de tabulador'].dt.year - 1).astype(str)
hsk['Fecha'] = hsk['Fecha de tabulador']
hsk['Fecha LY'] = hsk['Fecha'] - pd.DateOffset(years=1)

# %% [markdown]
# ## Ola 3 WE

# %%
# Convierte la columna a datetime por si acaso
hsk['Fecha de tabulador'] = pd.to_datetime(hsk['Fecha de tabulador'])

# Define la fecha de corte
fecha_corte = pd.Timestamp('2025-06-01')

# Filtro para Regi칩n WE y A침o 2025 y Fecha de tabulador >= 1/6/2025
filtro_we_ola3 = (
    (hsk['Fecha de tabulador'] >= fecha_corte) &
    (hsk['A침o'] == '2025') &
    (hsk['Regi칩n'] == 'WE')
)

# Para esas filas, asigna la primera aparici칩n de Fecha de tabulador a partir de 1/6/2025 para cada CeCo
primer_fecha_ola3 = (
    hsk.loc[filtro_we_ola3]
    .groupby('CeCo')['Fecha de tabulador']
    .first()
)

# Asigna el resultado solo a las filas que cumplen el filtro
hsk.loc[filtro_we_ola3, 'Fecha de ingreso a HSK'] = hsk.loc[filtro_we_ola3, 'CeCo'].map(primer_fecha_ola3)

# 游댳 Nuevo paso: actualizar Tipo a "OLA3" para esas filas
hsk.loc[filtro_we_ola3, 'validacion'] = "OLA3"

hsk['Wave'] = hsk['validacion']

# %% [markdown]
# ## Da formato a las columnas que utilizaremos

# %%
# Normaliza tipos en hsk
hsk['A침o'] = hsk['A침o'].astype(int).astype(str)
hsk['Mes'] = hsk['Mes'].astype(int).astype(str)
hsk['CeCo'] = hsk['CeCo'].astype(str)
hsk['# SK'] = hsk['# SK'].astype(str)

# Llaves y concatenaciones en hsk
hsk['concat_ay'] = hsk['CeCo'] + hsk['Mes'] + hsk['A침o']
hsk['concat_ly'] = hsk['CeCo'] + hsk['Mes'] + (hsk['A침o'].astype(int) - 1).astype(str)
hsk['llave_proveedor_ay'] = hsk['# SK'] + hsk['Mes'] + hsk['A침o']
hsk['Nombre SK'] = hsk['Nombre SK'].astype(str)
hsk['Nombre SK'] = hsk['Nombre SK'].astype(str)
hsk['llave_proveedor_ly'] = hsk['# SK'] + hsk['Mes'] + (hsk['A침o'].astype(int) - 1).astype(str)

# Normaliza tipos en acumulado_bajas
acumulado_bajas['A침o'] = acumulado_bajas['A침o'].astype(int).astype(str)
acumulado_bajas['Mes'] = acumulado_bajas['Mes'].astype(int).astype(str)
acumulado_bajas['NUMERO DE NEGOCIO'] = acumulado_bajas['NUMERO DE NEGOCIO'].astype(str)
acumulado_bajas['NUMERO DE PROVEEDOR'] = acumulado_bajas['NUMERO DE PROVEEDOR'].astype(str)

# Llaves y concatenaciones en acumulado_bajas
acumulado_bajas['concat_ay'] = acumulado_bajas['NUMERO DE NEGOCIO'] + acumulado_bajas['Mes'] + acumulado_bajas['A침o']
acumulado_bajas['concat_ly'] = acumulado_bajas['NUMERO DE NEGOCIO'] + acumulado_bajas['Mes'] + (acumulado_bajas['A침o'].astype(int) - 1).astype(str)
acumulado_bajas['llave_proveedor_ay'] = acumulado_bajas['NUMERO DE PROVEEDOR'] + acumulado_bajas['Mes'] + acumulado_bajas['A침o']
acumulado_bajas['llave_proveedor_ly'] = acumulado_bajas['NUMERO DE PROVEEDOR'] + acumulado_bajas['Mes'] + (acumulado_bajas['A침o'].astype(int) - 1).astype(str)

# Funci칩n de asignaci칩n de bajas
def agregar_bajas_a_hsk(hsk_df, bajas_df):
    conteo_ay = bajas_df['llave_proveedor_ay'].value_counts()
    conteo_ly = bajas_df['concat_ay'].value_counts()
    
    hsk_df['baja'] = hsk_df['llave_proveedor_ay'].map(conteo_ay).fillna(0).astype(int)
    hsk_df['baja ly'] = hsk_df['concat_ly'].map(conteo_ly).fillna(0).astype(int)
    
    return hsk_df

# Uso
hsk = agregar_bajas_a_hsk(hsk, acumulado_bajas)

# Crear diccionario de mapeo a partir de com_contrato
# Asegurar que las llaves del mapeo sean texto
map_dict = dict(zip(com_contrato['No.deNegocio'].astype(str), com_contrato['Tabulador 2025']))

# Asegurar que la columna CeCo sea texto antes de mapear
hsk['tradicional'] = hsk['CeCo'].astype(str).map(map_dict)

# %% [markdown]
# # Graduados

# %%
# Para contar aparici칩n acumulada de cada CeCo (1춹, 2춹, 3춹, etc.)
hsk['Aparicion'] = hsk.groupby('CeCo').cumcount() + 1

# Tambi칠n calculamos el n칰mero m치ximo de apariciones por CeCo
max_apariciones = hsk.groupby('CeCo')['Aparicion'].transform('max')

# Reemplazamos el n칰mero de la 칰ltima aparici칩n por "칔ltima"
hsk['Aparicion'] = hsk.apply(
    lambda row: 99999999 if row['Aparicion'] == max_apariciones[row.name] else row['Aparicion'],
    axis=1
)

hsk['Status'] = "Activa"

hsk['CeCo_count'] = hsk.groupby('CeCo')['CeCo'].transform('count')
hsk = hsk.sort_values('Fecha de tabulador')


def fill_pct_nuevo(group):
    mask = (group['Etapa'] == 'HSK Activo')
    # Solo para "HSK Activo", rellena hacia adelante (bfill)
    group.loc[mask, '% Nuevo'] = group.loc[mask, '% Nuevo'].bfill()
    return group

hsk = hsk.sort_values(['CeCo', 'Fecha de tabulador'])
hsk = hsk.groupby('CeCo', group_keys=False).apply(fill_pct_nuevo)

# Filtra el DataFrame para CeCo == '301372092' y muestra el resultado
# filtro = hsk[hsk['CeCo'] == '301372092']
# print(filtro)
# filtro.to_excel('aver.xlsx')


# %%
# Elimina duplicados en la columna 'Llave' y muestra cu치ntas filas se borraron
original_count = len(op_historico)
op_historico_sin_duplicados = op_historico.drop_duplicates(subset='Llave', keep='first')
final_count = len(op_historico_sin_duplicados)
print(f"Filas eliminadas por duplicados en 'Llave': {original_count - final_count}")

# %%
# Lookup para Sellout actual
hsk['Sellout'] = hsk['concat_ay'].map(
    op_historico_sin_duplicados.set_index('Llave')['Volumen Sell In (Hlts)']
)

# Lookup para Sellout ly
hsk['sellout ly'] = hsk['concat_ly'].map(
    op_historico_sin_duplicados.set_index('Llave')['Volumen Sell In (Hlts)']
)
# Lookup para Sellout actual
hsk['op'] = hsk['concat_ay'].map(
    op_historico_sin_duplicados.set_index('Llave')['EBIT']
)

# Lookup para Sellout ly
hsk['op ly'] = hsk['concat_ly'].map(
    op_historico_sin_duplicados.set_index('Llave')['EBIT']
)


# %%

# Normaliza tipos en acumulado_bajas
final_de_comisiones['A침o_Comision'] = final_de_comisiones['A침o_Comision'].astype(int).astype(str)
final_de_comisiones['Mes'] = final_de_comisiones['Mes'].astype(int).astype(str)
final_de_comisiones['No.SAPDENEGOCIO'] = final_de_comisiones['No.SAPDENEGOCIO'].astype(str)
final_de_comisiones['NoDEPROVEEDOR'] = final_de_comisiones['NoDEPROVEEDOR'].astype(str)
final_de_comisiones['Llave'] = final_de_comisiones['No.SAPDENEGOCIO'] + final_de_comisiones['NoDEPROVEEDOR'] + final_de_comisiones['Mes'] + final_de_comisiones['A침o_Comision']
final_de_comisiones['Llave2'] = final_de_comisiones['No.SAPDENEGOCIO'] + final_de_comisiones['Mes'] + final_de_comisiones['A침o_Comision']

hsk['Llave_Full'] = hsk['CeCo'] + hsk['Mes'] + hsk['A침o']
hsk['Llave_Full_ly'] = hsk['CeCo'] + hsk['Mes'] + (hsk['A침o'].astype(int) - 1).astype(str)

#lookup para Sellout actual
lookup = final_de_comisiones.groupby('Llave2')['Total Income'].max()
hsk['comision'] = hsk['Llave_Full'].map(lookup)
hsk['comision ly'] = hsk['Llave_Full_ly'].map(lookup)

hsk['Etapa']  = hsk['Etapa'].fillna('HSK Activo')

hsk["Fecha de tabulador"] = pd.to_datetime(hsk["Fecha de tabulador"]).dt.date
df_desincorporaciones["Mes Baja"] = pd.to_datetime(df_desincorporaciones["Mes Baja"]).dt.date
# Aplica la funci칩n de desincorporaciones
hsk = desincorporaciones(hsk, "CeCo", "Fecha de tabulador", df_desincorporaciones)
# Exporta
hsk.to_excel(r"C:\Users\dominh05\Documents\SIX\HSK\Resultados 2025\Historico Resultados HSK sin desinco.xlsx", index=False)
hsk.to_parquet(r"C:\Users\dominh05\Documents\SIX\HSK\Resultados 2025\hsk historico nuevo sin desinco.parquet", index=False)

# Filtra las filas de final_de_comisiones donde 'Llave' est치 duplicado
#duplicados = final_de_comisiones[final_de_comisiones.duplicated(subset='Llave', keep=False)]

# Exporta los duplicados a Excel
#duplicados.to_excel(r"C:\Users\dominh05\Documents\SIX\HSK\Resultados 2025\Llaves_duplicadas_final_de_comisiones.xlsx", index=False)



